{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c60a65e5-4d03-41a4-9fe3-4731012cad99",
   "metadata": {},
   "source": [
    "# Fine-tuning script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d251927-6ec1-4a38-ae01-5cfb2b45fb55",
   "metadata": {},
   "source": [
    "*Anusha, Joyce, Nina*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bf7cb-8cb3-49b8-9d1c-98ff46686ffd",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f60bbc-a2e8-4ad3-acdf-0ceba0a38fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, DataCollatorForTokenClassification, TrainingArguments\n",
    "from transformers.models.bert.configuration_bert import BertConfig \n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import csv\n",
    "from Bio import SeqIO\n",
    "#import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d38251-2066-40f6-84f3-c4412cba2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ids and comment out others when using\n",
    "princeton_id = 'aa8417'\n",
    "#princeton_id = 'ns...'\n",
    "#princeton_id = 'jf...'\n",
    "\n",
    "project_dir = f'/scratch/gpfs/{princeton_id}/QCB557_project'\n",
    "\n",
    "model_name = 'fine_tune_v1'\n",
    "model_out_dir = f'{project_dir}/models/{model_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89162e24-9c9d-4777-8310-3927638dacce",
   "metadata": {},
   "source": [
    "#### Load model and tokenizer from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9826f6a-6d87-47ee-8778-d9700397329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu\n",
    "device = 'cuda:0'\n",
    "\n",
    "config = BertConfig.from_pretrained(\"zhihan1996/DNABERT-2-117M\")\n",
    "config.num_labels #2 labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True, config=config)\n",
    "model.to(device)\n",
    "\n",
    "# don't need to move the tokenizer to gpu b/c it's light\n",
    "# use data collator to pad sequences dynamically during training\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29145c2e-c77f-40a4-aa65-319c242271e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f4262-11eb-4aae-81f2-62c264d798ea",
   "metadata": {},
   "source": [
    "#### Freeze and unfreeze gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a742af6-b655-4584-8605-62d74da0416f",
   "metadata": {},
   "source": [
    "We can play around with this later as we imrove the performance of the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f61d91-4d77-479c-b3e3-b622d5808ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default when using AutoModelForSequenceClassification is that all pretrained parameters/layers are frozen except classification head\n",
    "# as we go through rounds of fine-tuning, we can optionally unfreeze from of the pretrained layers to improve performance\n",
    "\n",
    "# unfreeze the last layer in the encoder block\n",
    "for name, param in model.named_parameters():\n",
    "    if \"encoder.layer.11\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f4bca-6dc8-4898-a2b7-9930fc378101",
   "metadata": {},
   "source": [
    "#### Load data from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8ad43-cd08-45f6-8ff8-e6698343d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_data_load(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, shuffle=True):\n",
    "        if shuffle:\n",
    "            self.dataframe = dataframe.sample(frac=1).reset_index(drop=True)  # shuffle the dataframe\n",
    "        else:\n",
    "            self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.dataframe.iloc[idx]['sequence']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "\n",
    "        # tokenize the sequence\n",
    "        # tokenizer automatically generates attention masks\n",
    "        inputs = self.tokenizer(sequence, padding='max_length', max_length=500, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        # move inputs to gpu\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da922b8-534d-4773-a9fe-ac32e9b9eb32",
   "metadata": {},
   "source": [
    "#### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ed7f8-af00-4d7d-b63f-3c9f7fcf2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_to_split = pd.read_csv(f'{project_dir}/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c0ca0d-f531-435e-bfcc-a46d801cd68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(f'{project_dir}/data/test.csv')\n",
    "test_ds = custom_data_load(dataframe = test_data, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485901b-5614-4d4b-a668-74e6faf88aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer, label_pad_token_id='X')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfda9b5-0eaa-402c-986f-f816eb07faa5",
   "metadata": {},
   "source": [
    "#### Split training into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc3169-165e-47f9-a278-ab2de4ac3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_test_split(train_data_to_split, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d4b7e-2a6b-4b07-b7be-43e3eedc27da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = custom_data_load(dataframe = train_data, tokenizer = tokenizer)\n",
    "valid_ds = custom_data_load(dataframe = valid_data, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da355e56-064b-4625-ba54-1aeaa748be55",
   "metadata": {},
   "source": [
    "#### Training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8aa17d-a48b-47bb-a685-413713e56bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = model_out_dir,\n",
    "    num_train_epochs= 10, \n",
    "    per_device_train_batch_size=16, # powers of 2\n",
    "    weight_decay=0.015, # regularization\n",
    "    learning_rate=1e-5,\n",
    "    gradient_accumulation_steps=2, # how many batches of gradients are accumulated before parameter update\n",
    "    gradient_checkpointing=True, # helps reduce memory\n",
    "    dataloader_num_workers=4,\n",
    "    \n",
    "    log_level=\"error\",\n",
    "    evaluation_strategy=\"steps\",  \n",
    "    eval_steps=500, \n",
    "    save_strategy=\"epoch\",        \n",
    "    logging_steps=500,\n",
    "    logging_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a242bb20-c06f-4a4a-8bcd-d10a9f05194a",
   "metadata": {},
   "source": [
    "#### Extra metrics to compute with validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fd445-39f5-48e9-9834-a7d32e194b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "    \n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd838666-2126-4080-a63c-849c2d97af5b",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f8d8e-dea0-4a9e-b72c-c1aff50508c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator = data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccecfa9-e5d8-4f76-a2bd-72bf6271cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.DataFrame(trainer.state.log_history)\n",
    "log_df.to_csv(f'{project_dir}/model_logs/log_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2d0a5-e052-46e9-94a9-5fed299162a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env [~/.conda/envs/torch-env/]",
   "language": "python",
   "name": "conda_torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
