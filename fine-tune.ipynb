{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c60a65e5-4d03-41a4-9fe3-4731012cad99",
   "metadata": {},
   "source": [
    "# Fine-tuning script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d251927-6ec1-4a38-ae01-5cfb2b45fb55",
   "metadata": {},
   "source": [
    "*Anusha, Joyce, Nina*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bf7cb-8cb3-49b8-9d1c-98ff46686ffd",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f60bbc-a2e8-4ad3-acdf-0ceba0a38fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89162e24-9c9d-4777-8310-3927638dacce",
   "metadata": {},
   "source": [
    "#### Load model and tokenizer from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9826f6a-6d87-47ee-8778-d9700397329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu\n",
    "device = 'cuda:0'\n",
    "\n",
    "config = BertConfig.from_pretrained(\"zhihan1996/DNABERT-2-117M\")\n",
    "model = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True, config=config).to(device)\n",
    "\n",
    "# don't need to move the tokenizer to gpu b/c it's light\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "tokenizer.pad_token = \"X\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f4262-11eb-4aae-81f2-62c264d798ea",
   "metadata": {},
   "source": [
    "#### Freeze gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f61d91-4d77-479c-b3e3-b622d5808ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze the last layer in the encoder block\n",
    "for name, param in model.named_parameters():\n",
    "    if \"encoder.layer.11\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f4bca-6dc8-4898-a2b7-9930fc378101",
   "metadata": {},
   "source": [
    "#### Load data from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8ad43-cd08-45f6-8ff8-e6698343d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_data_load(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, shuffle=True):\n",
    "        if shuffle:\n",
    "            self.dataframe = dataframe.sample(frac=1).reset_index(drop=True)  # shuffle the dataframe\n",
    "        else:\n",
    "            self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.dataframe.iloc[idx]['sequence']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "\n",
    "        # tokenize the sequence\n",
    "        # tokenizer automatically generates attention masks\n",
    "        inputs = self.tokenizer(sequence, padding='max_length', max_length=101, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        # move inputs to gpu\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25f40c0-d544-4985-80fb-d65094b9c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_to_csv(fasta_file, csv_file):\n",
    "    with open(fasta_file, 'r') as fasta_fh, open(csv_file, 'w', newline='') as csv_fh:\n",
    "        writer = csv.writer(csv_fh)\n",
    "        writer.writerow(['sequence', 'label'])\n",
    "        for record in SeqIO.parse(fasta_fh, 'fasta'):\n",
    "            label = record.id.split('|')[-1]\n",
    "            sequence = str(record.seq)\n",
    "            writer.writerow([sequence, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "597f3041-4074-439c-a8dd-156c58537293",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = '/scratch/gpfs/aa8417/QCB557_project/data/H3K4me3/train.fna'\n",
    "csv_file = '/scratch/gpfs/aa8417/QCB557_project/data/train.csv'\n",
    "fasta_to_csv(fasta_file, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78e2826e-709f-4b1e-8bf5-7bf746b72678",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = '/scratch/gpfs/aa8417/QCB557_project/data/H3K4me3/test.fna'\n",
    "csv_file = '/scratch/gpfs/aa8417/QCB557_project/data/test.csv'\n",
    "fasta_to_csv(fasta_file, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b05259-1203-4d4d-b9eb-56dd3b5cea1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
